<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Professor Pebble - English Practice AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { margin: 0; font-family: sans-serif; overflow: hidden; }
        #chat-container {
            height: 100vh;
            display: flex;
            flex-direction: column;
            background-color: #f0f2f5;
        }
        #chat-messages {
            flex-grow: 1;
            padding: 20px;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        .message {
            max-width: 80%;
            padding: 10px 15px;
            border-radius: 20px;
            word-wrap: break-word;
        }
        .user-message {
            background-color: #007bff;
            color: white;
            align-self: flex-end;
            border-bottom-right-radius: 5px;
        }
        .ai-message {
            background-color: #e2e2e2;
            color: #333;
            align-self: flex-start;
            border-bottom-left-radius: 5px;
        }
        .ai-message.correction {
            background-color: #ffe0b2; /* Light orange for corrections */
            border-left: 4px solid #ff9800; /* Orange border */
            padding-left: 11px; /* Adjust padding due to border */
        }
        #chat-input-area {
            display: flex;
            padding: 15px;
            background-color: #fff;
            border-top: 1px solid #ddd;
        }
        #user-input {
            flex-grow: 1;
            padding: 10px 15px;
            border: 1px solid #ddd;
            border-radius: 20px;
            outline: none;
            font-size: 16px;
        }
        #send-button, #speak-button {
            background-color: #28a745;
            color: white;
            border: none;
            border-radius: 20px;
            padding: 10px 15px;
            margin-left: 10px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.2s;
        }
        #send-button:hover, #speak-button:hover {
            background-color: #218838;
        }
        #avatar {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            margin-right: 10px;
            flex-shrink: 0;
        }
        .message-row {
            display: flex;
            align-items: flex-end;
        }
        .message-row.ai .message {
            margin-left: 10px;
        }
        .message-row.user {
            justify-content: flex-end;
        }
        #speaking-indicator {
            position: absolute;
            bottom: 80px; /* Adjust based on input area height */
            left: 20px;
            background-color: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 8px 12px;
            border-radius: 5px;
            font-size: 0.9em;
            display: none;
        }
    </style>
</head>
<body>
    <div id="chat-container">
        <div id="chat-messages">
            <div class="message-row ai">
                <img id="avatar" src="https://placehold.co/50x50/007bff/ffffff?text=Prof" alt="Professor Pebble Avatar">
                <div class="message ai-message">Hello! I'm Professor Pebble! Let's begin our sea adventure! Please say your first sea word or sentence.</div>
            </div>
        </div>
        <div id="speaking-indicator">Listening...</div>
        <div id="chat-input-area">
            <input type="text" id="user-input" placeholder="Type your message...">
            <button id="send-button">Send</button>
            <button id="speak-button">Speak</button>
        </div>
    </div>

    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";

        // The API key has been added here for GitHub Pages deployment.
        const API_KEY = "AIzaSyAk4N3yzJAXLBxCPXfUBEUfAciI7_Pdw2w"; 

        const genAI = new GoogleGenerativeAI(API_KEY);
        const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });

        const chatMessages = document.getElementById('chat-messages');
        const userInput = document.getElementById('user-input');
        const sendButton = document.getElementById('send-button');
        const speakButton = document.getElementById('speak-button');
        const speakingIndicator = document.getElementById('speaking-indicator');

        // Simulated student profiles (replace with actual backend integration for real data)
        const simulatedStudentProfiles = {
            "terry": { level: "Beginner", interests: "Yakisoba, robots, space", lastTopic: "greetings" },
            "sara": { level: "Intermediate", interests: "animals, nature, reading", lastTopic: "past tense" },
            "kenji": { level: "Advanced", interests: "history, technology, debate", lastTopic: "idioms" }
        };

        let currentStudent = null; // To store the profile of the current student

        // Web Speech API for voice input
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = SpeechRecognition ? new SpeechRecognition() : null;
        if (recognition) {
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                speakingIndicator.style.display = 'block';
                speakButton.textContent = 'Stop Speaking';
                speakButton.style.backgroundColor = '#dc3545'; // Red for stop
            };

            recognition.onresult = (event) => {
                const speechResult = event.results[0][0].transcript;
                userInput.value = speechResult;
                sendMessage(); // Send message automatically after speech
            };

            recognition.onspeechend = () => {
                speakingIndicator.style.display = 'none';
                speakButton.textContent = 'Speak';
                speakButton.style.backgroundColor = '#28a745'; // Green for speak
            };

            recognition.onerror = (event) => {
                speakingIndicator.style.display = 'none';
                speakButton.textContent = 'Speak';
                speakButton.style.backgroundColor = '#28a745'; // Green for speak
                console.error('Speech recognition error:', event.error);
                appendMessage("AI", "Sorry, I didn't catch that. Could you please type or try speaking again?", true);
            };
        } else {
            speakButton.style.display = 'none'; // Hide speak button if API not supported
        }

        // Web Speech API for voice output
        const synth = window.speechSynthesis;
        let speechUtterance = null;

        function speakText(text) {
            if (synth.speaking && speechUtterance) {
                synth.cancel(); // Stop current speech if any
            }
            speechUtterance = new SpeechSynthesisUtterance(text);
            speechUtterance.lang = 'en-US';
            speechUtterance.rate = 0.8; // Adjusted for slower speech
            speechUtterance.pitch = 1.0;
            synth.speak(speechUtterance);
        }

        function appendMessage(sender, text, isVoice = false) {
            const messageRow = document.createElement('div');
            messageRow.classList.add('message-row');
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('message');
            messageDiv.textContent = text;

            if (sender === 'user') {
                messageDiv.classList.add('user-message');
                messageRow.classList.add('user');
                messageRow.appendChild(messageDiv);
            } else {
                messageDiv.classList.add('ai-message');
                messageRow.classList.add('ai');
                const avatarImg = document.createElement('img');
                avatarImg.id = 'avatar';
                avatarImg.src = "https://placehold.co/50x50/007bff/ffffff?text=Prof";
                avatarImg.alt = "Professor Pebble Avatar";
                messageRow.appendChild(avatarImg);
                messageRow.appendChild(messageDiv);

                // Check for grammar correction phrases and add a special class
                const correctionPatterns = [
                    "The correct way to say that is:",
                    "Let's refine that:",
                    "A more natural way to say that is:",
                    "You almost got it! The correct form is:",
                    "Good try! Here's a small correction:",
                    "Try saying it this way:"
                ];
                const isCorrection = correctionPatterns.some(pattern => text.includes(pattern));
                if (isCorrection) {
                    messageDiv.classList.add('correction');
                }

                if (isVoice) { // Only speak AI messages that are specifically marked for voice output
                    speakText(text);
                }
            }
            chatMessages.appendChild(messageRow);
            chatMessages.scrollTop = chatMessages.scrollHeight; // Scroll to bottom
        }

        async function sendMessage() {
            const userText = userInput.value.trim();
            if (userText === '') return;

            appendMessage('user', userText);
            userInput.value = '';

            let context = `
<LLM_INSTRUCTION_SET>
  <ROLE_ASSIGNMENT>
    <PRIMARY_IDENTITY>Friendly_Robot_English_Teacher</PRIMARY_IDENTITY>
    <TARGET_LEARNER_PROFILE>
      <AGE_GROUP>Second_Grade_Elementary</AGE_GROUP>
      <ENGLISH_PROFICIENCY>Minimal_Interaction_Beginner</ENGLISH_PROFICIENCY>
    </TARGET_LEARNER_PROFILE>
    <CORE_PEDAGOGICAL_PRINCIPLES>
      <PRINCIPLE_1>Prioritize_Psychological_Safety</PRINCIPLE_1>
      <PRINCIPLE_2>Utilize_Positive_Reinforcement_Extensively</PRINCIPLE_2>
      <PRINCIPLE_3>Employ_Gentle_Correction_Techniques</PRINCIPLE_3>
      <PRINCIPLE_4>Encourage_Continuous_Verbal_Attempt</PRINCIPLE_4>
    </CORE_PEDAGOGICAL_PRINCIPLES>
  </ROLE_ASSIGNMENT>
  
  <INPUT_PROCESSING_RULES>
    <EXPECTED_INPUT_FORMAT>Simple_English_Words_Or_Short_Sentences</EXPECTED_INPUT_FORMAT>
    <TOPICAL_DOMAIN>Sea_And_Marine_Life_Vocabulary</TOPICAL_DOMAIN>
    <ILLUSTRATIVE_INPUT_EXAMPLES>
      <EXAMPLE_INPUT_A>Single_Noun_Word_Like_"fish"</EXAMPLE_INPUT_A>
      <EXAMPLE_INPUT_B>Adjective_Noun_Phrase_Like_"blue_boat"</EXAMPLE_INPUT_B>
      <EXAMPLE_INPUT_C>Simple_Verb_Phrase_Like_"I_can_swim"</EXAMPLE_INPUT_C>
    </ILLUSTRATIVE_INPUT_EXAMPLES>
  </INPUT_PROCESSING_RULES>
  
  <OUTPUT_GENERATION_RULES>
    <POSITIVE_FEEDBACK_STRATEGY>
      <CONDITION>Upon_Every_Student_Utterance_Attempt</CONDITION>
      <RESPONSE_VARIATIONS>
        <RESPONSE_A>Good_job!</RESPONSE_A>
        <RESPONSE_B>Wow!</RESPONSE_B>
        <RESPONSE_C>Excellent!</RESPONSE_C>
        <RESPONSE_D>Super!</RESPONSE_D>
        <RESPONSE_E>Fantastic!</RESPONSE_E>
      </RESPONSE_VARIATIONS>
    </POSITIVE_FEEDBACK_STRATEGY>
    <CORRECTION_STRATEGY>
      <CONDITION>If_Student_Utterance_Contains_Inaccuracy</CONDITION>
      <ACTION_SEQUENCE>
        <STEP_1>Gently_Repeat_Correct_Word_Or_Sentence_For_Student_To_Copy</STEP_1>
        <STEP_2>Explicitly_Avoid_Negative_Terms_Such_As_"wrong"_Or_"no"</STEP_2>
        <STEP_3>Immediately_Encourage_Another_Attempt_Without_Pressure</STEP_3>
      </ACTION_SEQUENCE>
    </CORRECTION_STRATEGY>
    <QUESTION_PROMPTING_STRATEGY>
      <QUESTION_TYPE>Simple_Contextual_And_Repetitive</QUESTION_TYPE>
      <QUESTION_RELEVANCE>Directly_Linked_To_Student's_Previous_Input_Or_Core_Vocabulary</QUESTION_RELEVANCE>
      <QUESTION_MAPPING_EXAMPLES>
        <MAPPING_1_VOCABULARY>
          <STUDENT_INPUT_CONTEXT>Naming_A_Sea_Animal</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"What_sea_animal_do_you_like?"</AI_RESPONSE_EXAMPLE>
        </MAPPING_1_VOCABULARY>
        <MAPPING_2_VOCABULARY>
          <STUDENT_INPUT_CONTEXT>Identifying_An_Object_From_Picture</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"Look_at_this_picture!_What_do_you_see?_(Imagine_there's_a_fish!)"</AI_RESPONSE_EXAMPLE>
        </MAPPING_2_VOCABULARY>
        <MAPPING_3_VOCABULARY>
          <STUDENT_INPUT_CONTEXT>Identifying_An_Object_From_Description</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"It's_a_shell._What_is_it?"</AI_RESPONSE_EXAMPLE>
        </MAPPING_3_VOCABULARY>
        <MAPPING_4_DESCRIPTIVE_PHRASES>
          <STUDENT_INPUT_CONTEXT>Describing_Color</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"It's_blue._What_color_is_it?"</AI_RESPONSE_EXAMPLE>
        </MAPPING_4_DESCRIPTIVE_PHRASES>
        <MAPPING_5_DESCRIPTIVE_PHRASES>
          <STUDENT_INPUT_CONTEXT>Describing_Size</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"It's_big._Is_it_big_or_small?"</AI_RESPONSE_EXAMPLE>
        </MAPPING_5_DESCRIPTIVE_PHRASES>
        <MAPPING_6_DESCRIPTIVE_PHRASES>
          <STUDENT_INPUT_CONTEXT>Combining_Color_And_Noun</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"It's_a_blue_fish._What_color_is_the_fish?"</AI_RESPONSE_EXAMPLE>
        </MAPPING_6_DESCRIPTIVE_PHRASES>
        <MAPPING_7_ACTIONS>
          <STUDENT_INPUT_CONTEXT>Stating_An_Ability</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"I_can_swim!_Can_you_swim?"</AI_RESPONSE_EXAMPLE>
        </MAPPING_7_ACTIONS>
        <MAPPING_8_ACTIONS>
          <STUDENT_INPUT_CONTEXT>Naming_An_Action</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"Dig._What_can_you_do_at_the_sea?"</AI_RESPONSE_EXAMPLE>
        </MAPPING_8_ACTIONS>
        <MAPPING_9_ACTIONS>
          <STUDENT_INPUT_CONTEXT>Confirming_Action</STUDENT_INPUT_CONTEXT>
          <AI_RESPONSE_EXAMPLE>"Play._Do_you_like_to_play?"</AI_RESPONSE_EXAMPLE>
        </MAPPING_9_ACTIONS>
      </QUESTION_MAPPING_EXAMPLES>
      <QUESTION_OBJECTIVE>Stimulate_Further_Simple_English_Production</QUESTION_OBJECTIVE>
    </QUESTION_PROMPTING_STRATEGY>
    <OVERALL_CONVERSATION_TONE>Consistently_Positive_And_Encouraging</OVERALL_CONVERSATION_TONE>
    <PRIMARY_INTERACTION_GOAL>Maximize_Student_Verbal_Participation_And_Confidence_Building</PRIMARY_INTERACTION_GOAL>
  </OUTPUT_GENERATION_RULES>
  
  <INITIATION_PROTOCOL>
    <START_PHRASE_OPTIONS>
      <OPTION_1>Let's_begin_our_sea_adventure!</OPTION_1>
      <OPTION_2>Please_say_your_first_sea_word_or_sentence.</OPTION_2>
    </START_PHRASE_OPTIONS>
  </INITIATION_PROTOCOL>
</LLM_INSTRUCTION_SET>
`;

            // Check for student name to load profile
            const nameMatch = userText.toLowerCase().match(/(?:my name is|i'm)\s+([a-z]+)/);
            if (nameMatch && simulatedStudentProfiles[nameMatch[1]]) {
                currentStudent = simulatedStudentProfiles[nameMatch[1]];
                context += `Current student is ${nameMatch[1]}. Their level is ${currentStudent.level}. Their interests are ${currentStudent.interests}. Their last practiced topic was ${currentStudent.lastTopic}. Please tailor your responses to this student.\n`;
            } else if (currentStudent) {
                context += `Currently conversing with ${currentStudent.level} level student whose interests include ${currentStudent.interests} and last topic was ${currentStudent.lastTopic}. Keep this context in mind.\n`;
            } else {
                context += "No specific student profile detected. Proceed with general English practice.\n";
            }

            const fullPrompt = `${context}\nStudent: ${userText}\nProfessor Pebble:`;

            try {
                const result = await model.generateContent(fullPrompt);
                const response = await result.response;
                const aiText = response.text();
                appendMessage('ai', aiText, true); // True to trigger voice output
            } catch (error) {
                console.error("Error communicating with Gemini API:", error);
                appendMessage('ai', "I apologize, but I'm having trouble connecting right now. Please try again later.", true);
            }
        }

        sendButton.addEventListener('click', sendMessage);
        userInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendMessage();
            }
        });

        speakButton.addEventListener('click', () => {
            if (recognition) {
                // Check if recognition is already active before starting
                if (recognition.recognizing) {
                    recognition.stop();
                } else {
                    recognition.start();
                }
            }
        });
    </script>
</body>
</html>
